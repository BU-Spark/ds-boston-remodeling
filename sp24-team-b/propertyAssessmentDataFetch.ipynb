{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Data From Property Assessment  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Database id by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.sqlDataFetch as sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_id = sdf.get_id_by_year(2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe The Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of each database have diff key value, I can not use for loop to get key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name          | Type      \n",
      "--------------------------------\n",
      "_id                  | int       \n",
      "PID                  | text      \n",
      "CM_ID                | text      \n",
      "ST_NUM               | text      \n",
      "ST_NAME              | text      \n",
      "ST_NAME_SUF          | text      \n",
      "UNIT_NUM             | text      \n",
      "ZIPCODE              | text      \n",
      "PTYPE                | text      \n",
      "LU                   | text      \n",
      "OWN_OCC              | text      \n",
      "OWNER                | text      \n",
      "MAIL_ADDRESS         | text      \n",
      "MAIL CS              | text      \n",
      "MAIL_ZIPCODE         | text      \n",
      "AV_LAND              | text      \n",
      "AV_BLDG              | text      \n",
      "AV_TOTAL             | text      \n",
      "GROSS_TAX            | text      \n",
      "LAND_SF              | text      \n",
      "YR_BUILT             | text      \n",
      "YR_REMOD             | text      \n",
      "GROSS_AREA           | text      \n",
      "LIVING_AREA          | text      \n",
      "NUM_FLOORS           | text      \n",
      "STRUCT_CLS           | text      \n",
      "R_BLDG_STYL          | text      \n",
      "R_ROOF_TYP           | text      \n",
      "R_EXT_FIN            | text      \n",
      "R_TOTAL_RMS          | text      \n",
      "R_BDRMS              | text      \n",
      "R_FULL_BTH           | text      \n",
      "R_HALF_BTH           | text      \n",
      "R_KITCH              | text      \n",
      "R_HEAT_TYP           | text      \n",
      "R_AC                 | text      \n",
      "R_FPLACE             | text      \n",
      "S_NUM_BLDG           | text      \n",
      "S_BLDG_STYL          | text      \n",
      "S_UNIT_RES           | text      \n",
      "S_UNIT_COM           | text      \n",
      "S_UNIT_RC            | text      \n",
      "S_EXT_FIN            | text      \n",
      "U_BASE_FLOOR         | text      \n",
      "U_NUM_PARK           | text      \n",
      "U_CORNER             | text      \n",
      "U_ORIENT             | text      \n",
      "U_TOT_RMS            | text      \n",
      "U_BDRMS              | text      \n",
      "U_FULL_BTH           | text      \n",
      "U_HALF_BTH           | text      \n",
      "U_KIT_TYPE           | text      \n",
      "U_HEAT_TYP           | text      \n",
      "U_AC                 | text      \n",
      "U_FPLACE             | text      \n"
     ]
    }
   ],
   "source": [
    "sdf.describe_database(database_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Con_unit, Res_unit, Rc_unit for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT\n",
      "    \"ZIPCODE\"::text AS ZIPCODE,\n",
      "    SUM(\"S_UNIT_RES\"::INT) AS total_res_units,\n",
      "    SUM(\"S_UNIT_COM\"::INT) AS total_com_units,\n",
      "    SUM(\"S_UNIT_RC\"::INT) AS total_rc_units\n",
      "FROM\n",
      "    \"1a374bd0-1ff9-4d1a-8727-ddfc201254fe\"\n",
      "GROUP BY\n",
      "    \"ZIPCODE\"::text\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://data.boston.gov/api/3/action/datastore_search_sql\"\n",
    "# Construct the SQL query to select distinct city names from the table\n",
    "sql_query = f\"\"\"\n",
    "SELECT\n",
    "    \"ZIPCODE\"::text AS ZIPCODE,\n",
    "    SUM(\"S_UNIT_RES\"::INT) AS total_res_units,\n",
    "    SUM(\"S_UNIT_COM\"::INT) AS total_com_units,\n",
    "    SUM(\"S_UNIT_RC\"::INT) AS total_rc_units\n",
    "FROM\n",
    "    \"{database_id}\"\n",
    "GROUP BY\n",
    "    \"ZIPCODE\"::text\n",
    "\"\"\"\n",
    "print(sql_query)\n",
    "params = {\"sql\": sql_query}\n",
    "\n",
    "# Send the request\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    # Check if there is data in the response\n",
    "    if data['success'] and 'result' in data and 'records' in data['result']:\n",
    "        records = data['result']['records']\n",
    "        # Filter records with ZIP code length greater than 1 and ensure ZIPCODE is not None\n",
    "        filtered_records = [record for record in records if record['zipcode'] and len(record['zipcode']) > 1]\n",
    "\n",
    "        # Convert the filtered records into a DataFrame\n",
    "        df = pd.DataFrame(filtered_records)\n",
    "    else:\n",
    "        print(\"No data found or error in response.\")\n",
    "else:\n",
    "    print(\"Failed to fetch data:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   zipcode  total_res_units  total_com_units  total_rc_units\n",
      "0    02090              NaN              NaN             NaN\n",
      "1    02108           1031.0            216.0             2.0\n",
      "2    02109           1199.0             84.0             8.0\n",
      "3    02110            872.0            273.0             0.0\n",
      "4    02111           1635.0            154.0           285.0\n",
      "5    02113           1132.0             38.0            28.0\n",
      "6    02114           3334.0            105.0             2.0\n",
      "7    02115           2806.0             47.0             3.0\n",
      "8    02116          15977.0            362.0           173.0\n",
      "9    02118           6709.0            199.0            25.0\n",
      "10   02119           1321.0             36.0             7.0\n",
      "11   02120            475.0              5.0             0.0\n",
      "12   02121            402.0              3.0             0.0\n",
      "13   02122           1384.0              6.0            10.0\n",
      "14   02124           1628.0             32.0            54.0\n",
      "15   02125           1655.0             15.0             2.0\n",
      "16   02126            357.0              2.0             0.0\n",
      "17   02127           6901.0             61.0            26.0\n",
      "18   02128           1345.0             24.0            10.0\n",
      "19   02129           3222.0             30.0             7.0\n",
      "20   02130           5586.0             39.0            51.0\n",
      "21   02131           1540.0             30.0            14.0\n",
      "22   02132           1504.0             15.0             2.0\n",
      "23   02133              NaN              NaN             NaN\n",
      "24   02134           2044.0             31.0             0.0\n",
      "25   02135           4117.0             26.0             2.0\n",
      "26   02136            582.0              5.0             0.0\n",
      "27   02137              NaN              NaN             NaN\n",
      "28   02199             15.0              0.0             0.0\n",
      "29   02210            580.0             29.0             0.0\n",
      "30   02215           2032.0             44.0             3.0\n",
      "31   02445              NaN              NaN             NaN\n",
      "32   02446              3.0              0.0             0.0\n",
      "33   02467            934.0              0.0             0.0\n"
     ]
    }
   ],
   "source": [
    "#df['zipcode'] = df['zipcode'].str.replace('_', '', regex=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save each cvs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_path = './data/cleaned/'\n",
    "file_name = 'property_assessment_2009.csv'\n",
    "full_path = os.path.join(save_path, file_name)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "  os.makedirs(save_path)\n",
    "\n",
    "df.to_csv(full_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
