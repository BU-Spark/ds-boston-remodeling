{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Data From Property Assessment  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Database id by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import data.sqlDataFetch as sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_id = sdf.get_id_by_year(2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe The Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of each database have diff key value, I can not use for loop to get key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name          | Type      \n",
      "--------------------------------\n",
      "_id                  | int       \n",
      "PID                  | text      \n",
      "CM_ID                | text      \n",
      "ST_NUM               | text      \n",
      "ST_NAME              | text      \n",
      "ST_NAME_SFX          | text      \n",
      "UNIT_NUM             | text      \n",
      "ZIPCODE              | text      \n",
      "PTYPE                | text      \n",
      "LU                   | text      \n",
      "OWN_OCC              | text      \n",
      "OWNER FY04           | text      \n",
      "MAIL_ADDRESS         | text      \n",
      "MAIL_CITY_STATE      | text      \n",
      "MAIL_ZIP             | text      \n",
      "LOTSIZE              | text      \n",
      "GROSS_AREA           | text      \n",
      "LIVING _AREA         | text      \n",
      "FY2004_TOTAL         | text      \n",
      "FY200_ LAND          | text      \n",
      "FY2004_BLDG          | text      \n",
      "GROSS_TAX            | text      \n",
      "NUM_FLOORS           | text      \n"
     ]
    }
   ],
   "source": [
    "sdf.describe_database(database_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Con_unit, Res_unit, Rc_unit for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT\n",
      "    \"ZIPCODE\"::text AS ZIPCODE,\n",
      "    SUM(\"LIVING _AREA\":: FLOAT) as TOTAL_LIVING_AREA\n",
      "FROM\n",
      "    \"5bfe4ca0-71c0-4751-bdcf-dad4d58445e0\"\n",
      "GROUP BY\n",
      "    \"ZIPCODE\"::text\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://data.boston.gov/api/3/action/datastore_search_sql\"\n",
    "# Construct the SQL query to select distinct city names from the table\n",
    "sql_query = f\"\"\"\n",
    "SELECT\n",
    "    \"ZIPCODE\"::text AS ZIPCODE,\n",
    "    SUM(\"LIVING _AREA\":: FLOAT) as TOTAL_LIVING_AREA\n",
    "FROM\n",
    "    \"{database_id}\"\n",
    "GROUP BY\n",
    "    \"ZIPCODE\"::text\n",
    "\"\"\"\n",
    "print(sql_query)\n",
    "params = {\"sql\": sql_query}\n",
    "\n",
    "# Send the request\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    # Check if there is data in the response\n",
    "    if data['success'] and 'result' in data and 'records' in data['result']:\n",
    "        records = data['result']['records']\n",
    "        # Filter records with ZIP code length greater than 1 and ensure ZIPCODE is not None\n",
    "        filtered_records = [record for record in records if record['zipcode'] and len(record['zipcode']) > 1]\n",
    "\n",
    "        # Convert the filtered records into a DataFrame\n",
    "        df = pd.DataFrame(filtered_records)\n",
    "    else:\n",
    "        print(\"No data found or error in response.\")\n",
    "else:\n",
    "    print(\"Failed to fetch data:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_zip_map = {\n",
    "    'Allston/Brighton': ['02134', '02135', '02163'],\n",
    "    'Back Bay/Beacon Hill': ['02108', '02116', '02117', '02123', '02133', '02199', '02216', '02217', '02295'],\n",
    "    'Central Boston': [\n",
    "        '02101', '02102', '02103', '02104', '02105', '02106', '02107', '02109', '02110', '02111',\n",
    "        '02112', '02113', '02114', '02196', '02201', '02202', '02203', '02204', '02205', '02206',\n",
    "        '02207', '02208', '02209', '02211', '02212', '02222', '02293'\n",
    "    ],\n",
    "    'Charlestown': ['02129'],\n",
    "    'Dorchester': ['02122', '02124', '02125'],\n",
    "    'East Boston': ['02128', '02228'],\n",
    "    'Fenway/Kenmore': ['02115', '02215'],\n",
    "    'Hyde Park': ['02136'],\n",
    "    'Jamaica Plain': ['02130'],\n",
    "    'Mattapan': ['02126'],\n",
    "    'Roslindale': ['02131'],\n",
    "    'Roxbury': ['02119', '02120', '02121'],\n",
    "    'South Boston': ['02127', '02210', '02219'],\n",
    "    'South End': ['02118'],\n",
    "    'West Roxbury': ['02132'],\n",
    "    'Dedham':['02026', '02137'],\n",
    "    ' Brookline':['02445', '02446', '02467', '02146'],\n",
    "    'Newton':['02458'],\n",
    "    ' Hingham':['02018'],\n",
    "    'Milton':['02186'],\n",
    "    'Westwood':['02090']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zipcode'] = df['zipcode'].astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zipcode'] = df['zipcode'].str.rstrip('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zip_neighborhood_map = {zip_code: neighborhood for neighborhood, zip_codes in neighborhood_zip_map.items() for zip_code in zip_codes}\n",
    "\n",
    "df['neighborhood'] = df['zipcode'].map(zip_neighborhood_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     zipcode  total_living_area neighborhood\n",
      "0      453-3              702.0          NaN\n",
      "1     1730-8              764.0          NaN\n",
      "2      106-N                0.0          NaN\n",
      "3      0F-46                0.0          NaN\n",
      "4      00247              845.0          NaN\n",
      "...      ...                ...          ...\n",
      "9731   0532B                0.0          NaN\n",
      "9732   62-53              444.0          NaN\n",
      "9733  W-23-2              575.0          NaN\n",
      "9734   129-1             4002.0          NaN\n",
      "9735   6-404              334.0          NaN\n",
      "\n",
      "[9736 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#df['zipcode'] = df['zipcode'].str.replace('_', '', regex=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save each cvs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_path = '../data/cleaned/'\n",
    "file_name = '2009.csv'\n",
    "full_path = os.path.join(save_path, file_name)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "  os.makedirs(save_path)\n",
    "\n",
    "df.to_csv(full_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "save_path = '../data/cleaned/'\n",
    "\n",
    "years = list(range(2009, 2024)) \n",
    "years.remove(2014)  \n",
    "years.append(2024)  \n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for year in years:\n",
    "    file_name = f'{year}.csv'\n",
    "    full_path = os.path.join(save_path, file_name)\n",
    "\n",
    "\n",
    "    temp_df = pd.read_csv(full_path)\n",
    "\n",
    "    temp_df['Year'] = year\n",
    "\n",
    "    combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
    "\n",
    "output_file_name = 'combined_2009_2024.csv'\n",
    "output_full_path = os.path.join(save_path, output_file_name)\n",
    "combined_df.to_csv(output_full_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
