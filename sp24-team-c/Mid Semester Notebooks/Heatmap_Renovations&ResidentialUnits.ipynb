{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Renovations Analysis in Boston\n",
    "\n",
    "## Introduction\n",
    "This notebook presents an analysis of housing renovations in Boston. The objective is to identify areas with the highest number of renovations and visualize them using a heat map. This is based on the client question: Where are housing remodels and renovations happening?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "In this section, we import the necessary Python libraries and set up our environment for analysis.\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "In this section, we load property data to identify buildings undergoing renovations. Additional features are retained to enhance our analysis and visualization of renovation trends across different locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:1: DtypeWarning: Columns (7,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2008 = pd.read_csv('../data/property_assessment_2008.csv')[['PID','LU', 'FY2008_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:4: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2009 = pd.read_csv('../data/property_assessment_2009.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:7: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2010 = pd.read_csv('../data/property_assessment_2010.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:8: DtypeWarning: Columns (14,26,27,28,34,35,38,42,45,46,49,50,51,52,53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2011 = pd.read_csv('../data/property_assessment_2011.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:9: DtypeWarning: Columns (14,43,47,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2012 = pd.read_csv('../data/property_assessment_2012.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:10: DtypeWarning: Columns (14,47,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2013 = pd.read_csv('../data/property_assessment_2013.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:12: DtypeWarning: Columns (15,46,53,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2014 = pd.read_csv('../data/property-assessment-fy2014.csv')[['Parcel_ID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:16: DtypeWarning: Columns (61,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2016 = pd.read_csv('../data/property_assessment_2016.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:17: DtypeWarning: Columns (61,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2017 = pd.read_csv('../data/property_assessment_2017.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:18: DtypeWarning: Columns (16,61,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2018 = pd.read_csv('../data/property_assessment_2018.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:19: DtypeWarning: Columns (16,61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2019 = pd.read_csv('../data/property_assessment_2019.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:20: DtypeWarning: Columns (7,16,28,29,30,35,36,37,38,39,40,41,42,43,45,46,47,48,49,59,60,65,66,67,68,69,70,71,73,74,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2020 = pd.read_csv('../data/property_assessment_2020.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2892757184.py:27: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pa_2024 = pd.read_csv('../data/property_assessment_2024.csv')[['PID','LU', 'TOTAL_VALUE', 'GROSS_AREA', 'LIVING_AREA', 'BED_RMS', 'YR_REMODEL', 'RES_UNITS', 'ZIP_CODE']]\n"
     ]
    }
   ],
   "source": [
    "pa_2008 = pd.read_csv('../data/property_assessment_2008.csv')[['PID','LU', 'FY2008_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']] \n",
    "# R_BDRMS = bedrooms, S_UNIT_RES' = residential units\n",
    "\n",
    "pa_2009 = pd.read_csv('../data/property_assessment_2009.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
    "# AV_TOTAL is now the total value of property\n",
    "\n",
    "pa_2010 = pd.read_csv('../data/property_assessment_2010.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
    "pa_2011 = pd.read_csv('../data/property_assessment_2011.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
    "pa_2012 = pd.read_csv('../data/property_assessment_2012.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
    "pa_2013 = pd.read_csv('../data/property_assessment_2013.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
    "\n",
    "pa_2014 = pd.read_csv('../data/property-assessment-fy2014.csv')[['Parcel_ID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
    "pa_2014.rename(columns={'Parcel_ID': 'PID'}, inplace=True)\n",
    "\n",
    "pa_2015 = pd.read_csv('../data/property_assessment_2015.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
    "pa_2016 = pd.read_csv('../data/property_assessment_2016.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
    "pa_2017 = pd.read_csv('../data/property_assessment_2017.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']] \n",
    "pa_2018 = pd.read_csv('../data/property_assessment_2018.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
    "pa_2019 = pd.read_csv('../data/property_assessment_2019.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
    "pa_2020 = pd.read_csv('../data/property_assessment_2020.csv')[['PID','LU', 'AV_TOTAL', 'GROSS_AREA', 'LIVING_AREA', 'R_BDRMS', 'YR_REMOD', 'S_UNIT_RES', 'ZIPCODE']]\n",
    "\n",
    "pa_2021 = pd.read_csv('../data/property_assessment_2021.csv')[['PID','LU', 'TOTAL_VALUE', 'GROSS_AREA', 'LIVING_AREA', 'BED_RMS', 'YR_REMODEL', 'RES_UNITS', 'ZIPCODE']]\n",
    "# AV_Total is now TOTAL_VALUE, R_BDRMS is now BED_RMS\n",
    "\n",
    "pa_2022 = pd.read_csv('../data/property_assessment_2022.csv')[['PID','LU', 'TOTAL_VALUE', 'GROSS_AREA', 'LIVING_AREA', 'BED_RMS', 'YR_REMODEL', 'RES_UNITS', 'ZIPCODE']]\n",
    "pa_2023 = pd.read_csv('../data/property_assessment_2023.csv')[['PID','LU', 'TOTAL_VALUE', 'GROSS_AREA', 'LIVING_AREA', 'BED_RMS', 'YR_REMODEL', 'RES_UNITS', 'ZIP_CODE']]\n",
    "pa_2024 = pd.read_csv('../data/property_assessment_2024.csv')[['PID','LU', 'TOTAL_VALUE', 'GROSS_AREA', 'LIVING_AREA', 'BED_RMS', 'YR_REMODEL', 'RES_UNITS', 'ZIP_CODE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the DataFrames in a dictionary for easier access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the DataFrames in a dictionary for easier access\n",
    "pa_df = {\n",
    "    2008: pa_2008,\n",
    "    2009: pa_2009,\n",
    "    2010: pa_2010,\n",
    "    2011: pa_2011,\n",
    "    2012: pa_2012,\n",
    "    2013: pa_2013,\n",
    "    2014: pa_2014,\n",
    "    2015: pa_2015,\n",
    "    2016: pa_2016,\n",
    "    2017: pa_2017,\n",
    "    2018: pa_2018,\n",
    "    2019: pa_2019,\n",
    "    2020: pa_2020,\n",
    "    2021: pa_2021,\n",
    "    2022: pa_2022,\n",
    "    2023: pa_2023,\n",
    "    2024: pa_2024,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change all remodelled years with col names 'YR_REMODEL' or 'YR_REMOD' to 'YR_REMODELLED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1         2000.0\n",
       "2         1985.0\n",
       "3         1991.0\n",
       "4         1978.0\n",
       "           ...  \n",
       "155559       NaN\n",
       "155560    1990.0\n",
       "155561    1998.0\n",
       "155562       NaN\n",
       "155563    2003.0\n",
       "Name: YR_REMODELLED, Length: 155564, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1         2000.0\n",
       "2         1985.0\n",
       "3         1991.0\n",
       "4         1978.0\n",
       "           ...  \n",
       "158087       NaN\n",
       "158088       NaN\n",
       "158089    1990.0\n",
       "158090    1998.0\n",
       "158091       NaN\n",
       "Name: YR_REMODELLED, Length: 158092, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         2001.0\n",
       "1            0.0\n",
       "2            0.0\n",
       "3         2002.0\n",
       "4         2004.0\n",
       "           ...  \n",
       "160078       NaN\n",
       "160079       NaN\n",
       "160080    1990.0\n",
       "160081    1998.0\n",
       "160082       NaN\n",
       "Name: YR_REMODELLED, Length: 160083, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1            NaN\n",
       "2            NaN\n",
       "3            NaN\n",
       "4            NaN\n",
       "           ...  \n",
       "161256    1997.0\n",
       "161257    2000.0\n",
       "161258    2000.0\n",
       "161259    2006.0\n",
       "161260       NaN\n",
       "Name: YR_REMODELLED, Length: 161261, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         1997.0\n",
       "1         1997.0\n",
       "2         1997.0\n",
       "3         1997.0\n",
       "4         1997.0\n",
       "           ...  \n",
       "164842    1990.0\n",
       "164843    2010.0\n",
       "164844       NaN\n",
       "164845       NaN\n",
       "164846       NaN\n",
       "Name: YR_REMODELLED, Length: 164847, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1         2000.0\n",
       "2         1985.0\n",
       "3         1991.0\n",
       "4         1978.0\n",
       "           ...  \n",
       "165603    1990.0\n",
       "165604    2010.0\n",
       "165605       NaN\n",
       "165606       NaN\n",
       "165607       NaN\n",
       "Name: YR_REMODELLED, Length: 165608, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            0\n",
       "1         2010\n",
       "2         1990\n",
       "3            0\n",
       "4            0\n",
       "          ... \n",
       "164086    1978\n",
       "164087    1991\n",
       "164088    1985\n",
       "164089    2000\n",
       "164090       0\n",
       "Name: YR_REMODELLED, Length: 164091, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            0.0\n",
       "1         2012.0\n",
       "2            0.0\n",
       "3            0.0\n",
       "4            0.0\n",
       "           ...  \n",
       "168110    2012.0\n",
       "168111    2009.0\n",
       "168112    2012.0\n",
       "168113    2009.0\n",
       "168114    2012.0\n",
       "Name: YR_REMODELLED, Length: 168115, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1            NaN\n",
       "2            NaN\n",
       "3            NaN\n",
       "4            NaN\n",
       "           ...  \n",
       "169194       NaN\n",
       "169195    2006.0\n",
       "169196       NaN\n",
       "169197    2006.0\n",
       "169198    2010.0\n",
       "Name: YR_REMODELLED, Length: 169199, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1         2000.0\n",
       "2         1985.0\n",
       "3         1991.0\n",
       "4         1978.0\n",
       "           ...  \n",
       "170905    1990.0\n",
       "170906    2010.0\n",
       "170907       NaN\n",
       "170908       NaN\n",
       "170909       NaN\n",
       "Name: YR_REMODELLED, Length: 170910, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1         2000.0\n",
       "2         1985.0\n",
       "3         1991.0\n",
       "4         1978.0\n",
       "           ...  \n",
       "172836    1990.0\n",
       "172837    2016.0\n",
       "172838       NaN\n",
       "172839       NaN\n",
       "172840       NaN\n",
       "Name: YR_REMODELLED, Length: 172841, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         2006.0\n",
       "1         1981.0\n",
       "2         2016.0\n",
       "3         1981.0\n",
       "4         2014.0\n",
       "           ...  \n",
       "174663    1990.0\n",
       "174664    2016.0\n",
       "174665       NaN\n",
       "174666       NaN\n",
       "174667       NaN\n",
       "Name: YR_REMODELLED, Length: 174668, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         2018.0\n",
       "1         2018.0\n",
       "2         2018.0\n",
       "3            NaN\n",
       "4            NaN\n",
       "           ...  \n",
       "175047    1999.0\n",
       "175048    2001.0\n",
       "175049    2001.0\n",
       "175050    1999.0\n",
       "175051    1999.0\n",
       "Name: YR_REMODELLED, Length: 175052, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1         2000.0\n",
       "2         1985.0\n",
       "3         1991.0\n",
       "4         1978.0\n",
       "           ...  \n",
       "177086       NaN\n",
       "177087       NaN\n",
       "177088    1990.0\n",
       "177089    2016.0\n",
       "177090       NaN\n",
       "Name: YR_REMODELLED, Length: 177091, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1         2000.0\n",
       "2         1985.0\n",
       "3         1991.0\n",
       "4         1978.0\n",
       "           ...  \n",
       "178593       NaN\n",
       "178594       NaN\n",
       "178595    1990.0\n",
       "178596    2016.0\n",
       "178597       NaN\n",
       "Name: YR_REMODELLED, Length: 178598, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1         2000.0\n",
       "2         1985.0\n",
       "3         1991.0\n",
       "4         1978.0\n",
       "           ...  \n",
       "180622       NaN\n",
       "180623       NaN\n",
       "180624    1990.0\n",
       "180625    2016.0\n",
       "180626       NaN\n",
       "Name: YR_REMODELLED, Length: 180627, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1         2000.0\n",
       "2         1985.0\n",
       "3         1991.0\n",
       "4         1978.0\n",
       "           ...  \n",
       "182237       NaN\n",
       "182238       NaN\n",
       "182239    1990.0\n",
       "182240    2016.0\n",
       "182241       NaN\n",
       "Name: YR_REMODELLED, Length: 182242, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through each year's DataFrame and filter it\n",
    "# Change all remodelled years with col names 'YR_REMODEL' or 'YR_REMOD' to 'YR_REMODELLED'\n",
    "for year, df in pa_df.items():\n",
    "    if 'YR_REMOD' in df.columns and 'YR_REMODEL' in df.columns:\n",
    "        # Use numpy's where function to create 'YR_REMODELLED' based on the condition\n",
    "        # that if 'YR_REMODEL' is not NaN (notna()), use 'YR_REMODEL', otherwise use 'YR_REMOD'\n",
    "        df['YR_REMODELLED'] = np.where(df['YR_REMODEL'].notna(), df['YR_REMODEL'], df['YR_REMOD'])\n",
    "\n",
    "    elif 'YR_REMOD' in df.columns:\n",
    "        # If only 'YR_REMOD' is available, copy its values to 'YR_REMODELLED'\n",
    "        df['YR_REMODELLED'] = df['YR_REMOD']\n",
    "\n",
    "    elif 'YR_REMODEL' in df.columns:\n",
    "        # If only 'YR_REMODEL' is available, copy its values to 'YR_REMODELLED'\n",
    "        df['YR_REMODELLED'] = df['YR_REMODEL']\n",
    "        \n",
    "    print(year)\n",
    "    display(df['YR_REMODELLED'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets replace for null values in the column feature 'YR_REMODELLED' with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, df in pa_df.items():\n",
    "    if 'YR_REMODELLED' in df.columns: \n",
    "        df['YR_REMODELLED'].replace(np.NaN, 0, inplace=True) \n",
    "\n",
    "    if 'YR_REMOD' in df.columns:\n",
    "        df.drop(columns=['YR_REMOD'], inplace=True)  # Add inplace=True here\n",
    "    if 'YR_REMODEL' in df.columns:\n",
    "        df.drop(columns=['YR_REMODEL'], inplace=True)  # And here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need change columns 'S_UNIT_RES' (2008-2020) to 'RES_UNITS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, df in pa_df.items():\n",
    "    if 'S_UNIT_RES' in df.columns:\n",
    "        df.rename(columns={'S_UNIT_RES': 'RES_UNITS'}, inplace=True)\n",
    "    df['RES_UNITS'] = df['RES_UNITS'].fillna(0)     \n",
    "    # print(year)\n",
    "    # display(df['RES_UNITS'])\n",
    "    # display(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get long and lat from Sam dataset and merge based on PID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d0/35z98j6s1_s8v_lhkt9b2wcw0000gn/T/ipykernel_28672/2498089124.py:1: DtypeWarning: Columns (8,9,24,25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sam_data = pd.read_csv('../data/neighborhood_data/Live_Street_Address_Management_(SAM)_Addresses.csv')[['PARCEL','X', 'Y']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>LU</th>\n",
       "      <th>FY2008_TOTAL</th>\n",
       "      <th>GROSS_AREA</th>\n",
       "      <th>LIVING_AREA</th>\n",
       "      <th>R_BDRMS</th>\n",
       "      <th>RES_UNITS</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>YR_REMODELLED</th>\n",
       "      <th>DATA_YEAR</th>\n",
       "      <th>AV_TOTAL</th>\n",
       "      <th>TOTAL_VALUE</th>\n",
       "      <th>BED_RMS</th>\n",
       "      <th>ZIP_CODE</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001000</td>\n",
       "      <td>R3</td>\n",
       "      <td>365200.0</td>\n",
       "      <td>3353.0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.032609</td>\n",
       "      <td>42.379420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001000</td>\n",
       "      <td>R3</td>\n",
       "      <td>365200.0</td>\n",
       "      <td>3353.0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.032601</td>\n",
       "      <td>42.379409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001000</td>\n",
       "      <td>R3</td>\n",
       "      <td>365200.0</td>\n",
       "      <td>3353.0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.032601</td>\n",
       "      <td>42.379409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001000</td>\n",
       "      <td>R3</td>\n",
       "      <td>365200.0</td>\n",
       "      <td>3353.0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.032601</td>\n",
       "      <td>42.379409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001000</td>\n",
       "      <td>R3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3353.0</td>\n",
       "      <td>2202.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>270500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.032609</td>\n",
       "      <td>42.379420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID  LU  FY2008_TOTAL  GROSS_AREA  LIVING_AREA  R_BDRMS  RES_UNITS  \\\n",
       "0  100001000  R3      365200.0      3353.0       2202.0      6.0        0.0   \n",
       "1  100001000  R3      365200.0      3353.0       2202.0      6.0        0.0   \n",
       "2  100001000  R3      365200.0      3353.0       2202.0      6.0        0.0   \n",
       "3  100001000  R3      365200.0      3353.0       2202.0      6.0        0.0   \n",
       "4  100001000  R3           NaN      3353.0       2202.0      6.0        0.0   \n",
       "\n",
       "  ZIPCODE  YR_REMODELLED  DATA_YEAR  AV_TOTAL TOTAL_VALUE  BED_RMS  ZIP_CODE  \\\n",
       "0  2128.0            0.0       2008       NaN         NaN      NaN       NaN   \n",
       "1  2128.0            0.0       2008       NaN         NaN      NaN       NaN   \n",
       "2  2128.0            0.0       2008       NaN         NaN      NaN       NaN   \n",
       "3  2128.0            0.0       2008       NaN         NaN      NaN       NaN   \n",
       "4  2128.0            0.0       2009  270500.0         NaN      NaN       NaN   \n",
       "\n",
       "    latitude  longitude  \n",
       "0 -71.032609  42.379420  \n",
       "1 -71.032601  42.379409  \n",
       "2 -71.032601  42.379409  \n",
       "3 -71.032601  42.379409  \n",
       "4 -71.032609  42.379420  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sam_data = pd.read_csv('../data/neighborhood_data/Live_Street_Address_Management_(SAM)_Addresses.csv')[['PARCEL','X', 'Y']]\n",
    "\n",
    "# Function to merge data with SAM data to get lat and long\n",
    "def merge_with_sam(data, sam_data):\n",
    "    # Merge on 'PID' from data and 'PARCEL' from sam_data\n",
    "    merged_data = pd.merge(data, sam_data, left_on='PID', right_on='PARCEL')\n",
    "\n",
    "    # Dropping the 'PARCEL' column as 'PARCEL' and 'PID' are the same\n",
    "    merged_data.drop(columns=['PARCEL'], inplace=True)\n",
    "\n",
    "    # Rename 'X' to 'latitude' and 'Y' to 'longitude'\n",
    "    merged_data.rename(columns={'X': 'latitude', 'Y': 'longitude'}, inplace=True)\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "\n",
    "#Create a dataset for all years for simplicity\n",
    "for year, df in pa_df.items():\n",
    "    df['DATA_YEAR'] = year\n",
    "    \n",
    "dataframes = [df for year, df in pa_df.items()]\n",
    "\n",
    "# Now concatenate those DataFrames\n",
    "all_data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Merge data\n",
    "all_data_merged = merge_with_sam(all_data, sam_data)\n",
    "\n",
    "display(all_data_merged.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows where R_UNITS is 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping: 2916571\n",
      "Number of rows after dropping: 387876\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>LU</th>\n",
       "      <th>FY2008_TOTAL</th>\n",
       "      <th>GROSS_AREA</th>\n",
       "      <th>LIVING_AREA</th>\n",
       "      <th>R_BDRMS</th>\n",
       "      <th>RES_UNITS</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>YR_REMODELLED</th>\n",
       "      <th>DATA_YEAR</th>\n",
       "      <th>AV_TOTAL</th>\n",
       "      <th>TOTAL_VALUE</th>\n",
       "      <th>BED_RMS</th>\n",
       "      <th>ZIP_CODE</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>100018000</td>\n",
       "      <td>CM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2128</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.031161</td>\n",
       "      <td>42.379909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>100018000</td>\n",
       "      <td>CM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2128</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.031161</td>\n",
       "      <td>42.379909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>100018000</td>\n",
       "      <td>CM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2128</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.031161</td>\n",
       "      <td>42.379909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>100018000</td>\n",
       "      <td>CM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2128</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.031161</td>\n",
       "      <td>42.379909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>100018000</td>\n",
       "      <td>CM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2128.0</td>\n",
       "      <td>-71.031161</td>\n",
       "      <td>42.379909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PID  LU  FY2008_TOTAL  GROSS_AREA  LIVING_AREA  R_BDRMS  RES_UNITS  \\\n",
       "885  100018000  CM           NaN         NaN          NaN      NaN        4.0   \n",
       "886  100018000  CM           NaN         NaN          NaN      NaN        4.0   \n",
       "887  100018000  CM           NaN         NaN          NaN      NaN        4.0   \n",
       "888  100018000  CM           NaN         NaN          NaN      NaN        4.0   \n",
       "889  100018000  CM           NaN         NaN          NaN      NaN        4.0   \n",
       "\n",
       "    ZIPCODE  YR_REMODELLED  DATA_YEAR  AV_TOTAL TOTAL_VALUE  BED_RMS  \\\n",
       "885    2128         2018.0       2022       NaN           0      8.0   \n",
       "886    2128         2018.0       2022       NaN           0      8.0   \n",
       "887    2128         2018.0       2022       NaN           0      8.0   \n",
       "888    2128         2018.0       2022       NaN           0      8.0   \n",
       "889     NaN            0.0       2023       NaN           0      NaN   \n",
       "\n",
       "     ZIP_CODE   latitude  longitude  \n",
       "885       NaN -71.031161  42.379909  \n",
       "886       NaN -71.031161  42.379909  \n",
       "887       NaN -71.031161  42.379909  \n",
       "888       NaN -71.031161  42.379909  \n",
       "889    2128.0 -71.031161  42.379909  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data_merged['RES_UNITS'] = all_data_merged['RES_UNITS'].fillna(0)\n",
    "\n",
    "# Determine the number of rows before dropping\n",
    "rows_before = all_data_merged.shape[0]\n",
    "print(f\"Number of rows before dropping: {rows_before}\")\n",
    "\n",
    "# Drop rows where 'RES_UNITS' is zero\n",
    "all_data_merged = all_data_merged[all_data_merged['RES_UNITS'] != 0]\n",
    "\n",
    "# Determine the number of rows after dropping\n",
    "rows_after = all_data_merged.shape[0]\n",
    "print(f\"Number of rows after dropping: {rows_after}\")\n",
    "\n",
    "# Optionally, display the first few rows of the DataFrame after dropping the rows\n",
    "display(all_data_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Changes in Residential Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>REMODEL_YEAR</th>\n",
       "      <th>RES_UNITS_change</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101399100</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-70.995581</td>\n",
       "      <td>42.389219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101399100</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-70.995581</td>\n",
       "      <td>42.389219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101399100</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-70.995581</td>\n",
       "      <td>42.389219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101399100</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-70.995581</td>\n",
       "      <td>42.389219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101399100</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-70.995811</td>\n",
       "      <td>42.389369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID  REMODEL_YEAR  RES_UNITS_change   latitude  longitude\n",
       "0  101399100        2016.0               0.0 -70.995581  42.389219\n",
       "1  101399100        2016.0               0.0 -70.995581  42.389219\n",
       "2  101399100        2016.0               0.0 -70.995581  42.389219\n",
       "3  101399100        2016.0               0.0 -70.995581  42.389219\n",
       "4  101399100        2016.0               0.0 -70.995811  42.389369"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows_to_append = []  # Initialize an empty list to collect DataFrames\n",
    "\n",
    "# Loop over each PID and process the groups\n",
    "for pid, group in all_data_merged.groupby('PID'):\n",
    "    # Ensure the group is sorted by year\n",
    "    group = group.sort_values(by='DATA_YEAR')\n",
    "    \n",
    "    # Get all the remodel years for the PID that fall between 2008 and 2023\n",
    "    remodel_years = group.loc[group['YR_REMODELLED'].between(2008, 2023), 'YR_REMODELLED'].unique()\n",
    "\n",
    "    for remodel_year in remodel_years:\n",
    "        remodel_year_int = int(remodel_year)  # Convert to integer\n",
    "\n",
    "        # Find the data entry before the renovation\n",
    "        pre_remodel_data = group[group['DATA_YEAR'] < remodel_year].iloc[-1:]\n",
    "\n",
    "        # Find the data entry after the renovation\n",
    "        after_remodel_data = pd.DataFrame()\n",
    "        for year in range(remodel_year_int, 2024):\n",
    "            after_data = group[group['DATA_YEAR'] == year]\n",
    "            if not after_data.empty and (after_data['YR_REMODELLED'] == remodel_year).any():\n",
    "                after_remodel_data = after_data[after_data['YR_REMODELLED'] == remodel_year].copy()\n",
    "                after_remodel_data.loc[:, 'REMODEL_YEAR'] = remodel_year\n",
    "                break\n",
    "\n",
    "        # Calculate the change in residential units if both before and after data exist\n",
    "        if not pre_remodel_data.empty and not after_remodel_data.empty:\n",
    "            pre_remodel_data = pre_remodel_data.copy()\n",
    "            pre_remodel_data.loc[:, 'REMODEL_YEAR'] = remodel_year\n",
    "\n",
    "            # Calculate the change in RES_UNITS\n",
    "            units_change = after_remodel_data['RES_UNITS'].values[0] - pre_remodel_data['RES_UNITS'].values[0]\n",
    "            after_remodel_data.loc[:, 'RES_UNITS_change'] = units_change\n",
    "\n",
    "            # Keep the necessary columns and append the data for visualization\n",
    "            relevant_data = after_remodel_data[['PID', 'REMODEL_YEAR', 'RES_UNITS_change', 'latitude', 'longitude']].copy()\n",
    "            rows_to_append.append(relevant_data)\n",
    "\n",
    "# Concatenate all rows into a DataFrame\n",
    "res_units_renovation_comparison = pd.concat(rows_to_append, ignore_index=True)\n",
    "\n",
    "# Next steps would involve spatially joining this data with neighborhood boundaries\n",
    "# and visualizing the changes in residential units in the same manner as done before\n",
    "display(res_units_renovation_comparison.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the GeoJSON file to understand the structure of the neighborhood boundaries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "../data/neighborhood_data/BPDA_Neighborhood_Boundaries.geojson: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mfiona/ogrext.pyx:136\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: ../data/neighborhood_data/BPDA_Neighborhood_Boundaries.geojson: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the GeoJSON file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m neighborhood_boundaries \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/neighborhood_data/BPDA_Neighborhood_Boundaries.geojson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Display the first few rows to verify the structure\u001b[39;00m\n\u001b[1;32m      7\u001b[0m display(neighborhood_boundaries)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/geopandas/io/file.py:297\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_fiona\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/geopandas/io/file.py:338\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[1;32m    339\u001b[0m         crs \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;66;03m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/fiona/env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/fiona/__init__.py:292\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43menabled_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    303\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    304\u001b[0m         path,\n\u001b[1;32m    305\u001b[0m         mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    315\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/fiona/collection.py:243\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:588\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:143\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: ../data/neighborhood_data/BPDA_Neighborhood_Boundaries.geojson: No such file or directory"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load the GeoJSON file\n",
    "neighborhood_boundaries = gpd.read_file('../data/neighborhood_data/BPDA_Neighborhood_Boundaries.geojson')\n",
    "\n",
    "# Display the first few rows to verify the structure\n",
    "display(neighborhood_boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate Changes with Neighborhoods (Convert property data into a GeoDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "# Assuming 'latitude' and 'longitude' columns exist in your dataset\n",
    "property_geo = gpd.GeoDataFrame(res_units_renovation_comparison, geometry=gpd.points_from_xy(res_units_renovation_comparison.latitude, res_units_renovation_comparison.longitude))\n",
    "display(property_geo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a spatial join with the neighborhood boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both GeoDataFrames use the same CRS\n",
    "property_geo = property_geo.set_crs(neighborhood_boundaries.crs)\n",
    "\n",
    "# Spatial join\n",
    "properties_with_neighborhoods = gpd.sjoin(property_geo, neighborhood_boundaries, how='inner', op='intersects')\n",
    "display(properties_with_neighborhoods.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the changes in residential units by neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_units_by_neighborhood = properties_with_neighborhoods.groupby('name')['RES_UNITS_change'].sum().reset_index()\n",
    "\n",
    "display(res_units_by_neighborhood.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'RES_UNITS_change' in neighborhood_boundaries.columns:\n",
    "    neighborhood_boundaries.drop(columns=['RES_UNITS_change'])\n",
    "neighborhood_boundaries = neighborhood_boundaries.merge(res_units_by_neighborhood, on='name', how='left')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Define colors based on increase/decrease in residential units\n",
    "neighborhood_boundaries['color'] = 'white'  # Default color for no change\n",
    "neighborhood_boundaries.loc[neighborhood_boundaries['RES_UNITS_change'] > 0, 'color'] = 'green'  # Increase\n",
    "neighborhood_boundaries.loc[neighborhood_boundaries['RES_UNITS_change'] < 0, 'color'] = 'red'    # Decrease\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(30, 30))\n",
    "\n",
    "# Plot using custom colors\n",
    "neighborhood_boundaries.plot(ax=ax, color=neighborhood_boundaries['color'], edgecolor='black', linewidth=0.5)\n",
    "\n",
    "# Add lines for areas with missing data\n",
    "missing_data_areas = neighborhood_boundaries[pd.isnull(neighborhood_boundaries['RES_UNITS_change'])]\n",
    "missing_data_areas.plot(ax=ax, color=\"white\", hatch=\"////\", edgecolor=\"black\", linewidth=1)\n",
    "\n",
    "# Custom legend\n",
    "red_patch = mpatches.Patch(color='red', label='Decrease in residential units')\n",
    "green_patch = mpatches.Patch(color='green', label='Increase in residential units')\n",
    "white_patch = mpatches.Patch(color='white', label='No change in residential units')\n",
    "plt.legend(handles=[red_patch, green_patch, white_patch], loc='upper left', fontsize=23)\n",
    "\n",
    "# Annotations for RES_UNITS change and neighborhood name\n",
    "for idx, row in neighborhood_boundaries.iterrows():\n",
    "    if pd.notnull(row['RES_UNITS_change']):\n",
    "        if row['name'] == 'Chinatown':\n",
    "            # Adjust position for Chinatown label\n",
    "            ax.annotate(f\"{int(row['RES_UNITS_change'])}\\n{row['name']}\", \n",
    "                        xy=(row['geometry'].centroid.x, row['geometry'].centroid.y + 0.005),  # Adjust Y position\n",
    "                        horizontalalignment='center', verticalalignment='center',\n",
    "                        fontsize=20, color='black')\n",
    "        elif row['name'] == 'Bay Village':\n",
    "            # Adjust position for Chinatown label\n",
    "            ax.annotate(f\"{int(row['RES_UNITS_change'])}\\n{row['name']}\", \n",
    "                        xy=(row['geometry'].centroid.x, row['geometry'].centroid.y - 0.002),  # Adjust Y position\n",
    "                        horizontalalignment='center', verticalalignment='center',\n",
    "                        fontsize=20, color='black')\n",
    "        elif row['name'] == 'South Boston Waterfront':\n",
    "            # Adjust position for Chinatown label\n",
    "            ax.annotate(f\"{int(row['RES_UNITS_change'])}\\n{row['name']}\", \n",
    "                        xy=(row['geometry'].centroid.x + 0.008, row['geometry'].centroid.y - 0.002),  # Adjust Y position\n",
    "                        horizontalalignment='center', verticalalignment='center',\n",
    "                        fontsize=20, color='black')\n",
    "        else:\n",
    "            ax.annotate(f\"{int(row['RES_UNITS_change'])}\\n{row['name']}\", \n",
    "                        xy=(row['geometry'].centroid.x, row['geometry'].centroid.y),\n",
    "                        horizontalalignment='center', verticalalignment='center',\n",
    "                        fontsize=20, color='black')\n",
    "\n",
    "plt.title('Change in Residential Units per Neighborhood', fontsize=23)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
